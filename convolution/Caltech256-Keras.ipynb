{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the directory structure in Keras style\n",
    "\n",
    "**ONLY DO THIS ONCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import collections\n",
    "def structure_dir(dir_name):\n",
    "    base_path = \"/root/nbs/data/256_ObjectCategories_Stratified/\"\n",
    "    for i in range(1, 258):\n",
    "        os.mkdir(base_path + \"%s/%s\" % (dir_name, i))\n",
    "    for f in os.listdir(base_path + dir_name):\n",
    "        if 'jpg' in f:\n",
    "            d = int(f.split(\"_\")[0])\n",
    "            a = base_path + dir_name + \"/\" + f\n",
    "            b = base_path + dir_name + \"/\" + str(d) + \"/\" + f\n",
    "            os.rename(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure_dir('valid')\n",
    "structure_dir('train')\n",
    "structure_dir('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/256_ObjectCategories_Stratified/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '6185' (I am process '6774')\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    " from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "import bcolz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an empty Keras model, then load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: subtract the mean?\n",
    "batch_size = 64\n",
    "input_shape = (3, 224, 224)\n",
    "img_input = Input(shape=input_shape)\n",
    "# Block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "# dense\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "model_full = Model(img_input, x, name='vgg16_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n",
    "weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels.h5', WEIGHTS_PATH, cache_subdir='models')\n",
    "model_full.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab just the convolutional layers, and use them to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [i for i,l in enumerate(model_full.layers) if type(l) is Conv2D][-1]\n",
    "conv_layers = model_full.layers[:last_conv_idx + 2]  # max pooling is last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv_layer = conv_layers[-1]\n",
    "model = Model(img_input, last_conv_layer.get_output_at(0), name='vgg16_conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20812 images belonging to 257 classes.\n",
      "Found 3673 images belonging to 257 classes.\n",
      "Found 6122 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "# Do not shuffle the data! You'll lose the label ordering\n",
    "generator = image.ImageDataGenerator()\n",
    "batches = generator.flow_from_directory(path + 'train', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "val_batches = generator.flow_from_directory(path + 'valid', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "test_batches = generator.flow_from_directory(path + 'test', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and save the featurized arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /root/.theano/compiledir_Linux-4.4-amzn1.x86_64-x86_64-with-glibc2.2.5-x86_64-3.5.3-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 18s, sys: 2min, total: 13min 19s\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat = model.predict_generator(batches, int(batches.samples / batch_size) + 1)\n",
    "conv_val_feat = model.predict_generator(val_batches, int(val_batches.samples / batch_size) + 1)\n",
    "conv_test_feat = model.predict_generator(test_batches, int(test_batches.samples / batch_size) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path + 'results'):\n",
    "    os.mkdir(path + 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train = bcolz.carray(conv_feat, rootdir=path + 'results/conv_feat.dat')\n",
    "c_train.flush()\n",
    "c_val = bcolz.carray(conv_val_feat, rootdir=path + 'results/conv_val_feat.dat')\n",
    "c_val.flush()\n",
    "c_test = bcolz.carray(conv_test_feat, rootdir=path + 'results/conv_test_feat.dat')\n",
    "c_test.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = bcolz.open(path + 'results/conv_feat.dat')\n",
    "conv_val_feat = bcolz.open(path + 'results/conv_val_feat.dat')\n",
    "conv_test_feat = bcolz.open(path + 'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20812, 512, 7, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dense layers, then copy weights that were loaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_input = Input(shape=(512, 7, 7))\n",
    "y = Flatten(name='flatten')(feat_input)\n",
    "y = Dense(4096, activation='relu', name='fc1')(y)\n",
    "y = Dense(4096, activation='relu', name='fc2')(y)\n",
    "y = Dropout(rate=0.2)(y)\n",
    "y = Dense(257, activation='softmax', name='predictions')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_top = Model(feat_input, y, name='vgg16_top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer_name in ['fc1', 'fc2']:\n",
    "    model_top.get_layer(layer_name).set_weights(model_full.get_layer(layer_name).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer_name in ['fc1', 'fc2']:\n",
    "    model_top.get_layer(layer_name).trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "(val_classes, trn_classes, val_labels, trn_labels) = \\\n",
    "(val_batches.classes, batches.classes, to_categorical(val_batches.classes), to_categorical(batches.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/2\n",
      "20812/20812 [==============================] - 15s - loss: 3.6673 - acc: 0.3170 - val_loss: 1.7736 - val_acc: 0.5826\n",
      "Epoch 2/2\n",
      "20812/20812 [==============================] - 15s - loss: 1.5242 - acc: 0.6274 - val_loss: 1.3964 - val_acc: 0.6610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cee21bb00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_top.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=2, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 15s - loss: 1.0815 - acc: 0.7207 - val_loss: 1.2822 - val_acc: 0.6885\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.8206 - acc: 0.7810 - val_loss: 1.2241 - val_acc: 0.7062\n",
      "Epoch 3/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.6480 - acc: 0.8236 - val_loss: 1.1945 - val_acc: 0.7130\n",
      "Epoch 4/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.5129 - acc: 0.8562 - val_loss: 1.1845 - val_acc: 0.7169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cee683b00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/2\n",
      "20812/20812 [==============================] - 15s - loss: 0.4148 - acc: 0.8858 - val_loss: 1.1821 - val_acc: 0.7231\n",
      "Epoch 2/2\n",
      "20812/20812 [==============================] - 15s - loss: 0.3330 - acc: 0.9089 - val_loss: 1.1853 - val_acc: 0.7288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cee725208>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top.optimizer.lr = 0.00001\n",
    "model_top.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=2, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.2730 - acc: 0.9296 - val_loss: 1.1904 - val_acc: 0.7275\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.2253 - acc: 0.9422 - val_loss: 1.1891 - val_acc: 0.7264\n",
      "Epoch 3/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.1848 - acc: 0.9566 - val_loss: 1.1892 - val_acc: 0.7332\n",
      "Epoch 4/4\n",
      "20812/20812 [==============================] - 15s - loss: 0.1574 - acc: 0.9663 - val_loss: 1.1951 - val_acc: 0.7307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cee6429e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_top.save(path + 'results/vgg16_top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train output + fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "feat_input = Input(shape=(512, 7, 7))\n",
    "y = Flatten(name='flatten')(feat_input)\n",
    "y = Dense(4096, activation='relu', name='fc1')(y)\n",
    "# y = Dropout(rate=0.3)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(4096, activation='relu', name='fc2', kernel_regularizer=regularizers.l2(0.05))(y)\n",
    "# y = Dropout(rate=0.3)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(257, activation='softmax', name='predictions', kernel_regularizer=regularizers.l2(0.05))(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fc2 = Model(feat_input, y, name='vgg16_fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer_name in ['fc1']:\n",
    "    model_fc2.get_layer(layer_name).set_weights(model_full.get_layer(layer_name).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer_name in ['fc1']:\n",
    "    model_fc2.get_layer(layer_name).trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20812 images belonging to 257 classes.\n",
      "Found 3673 images belonging to 257 classes.\n",
      "Found 6122 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "# Do not shuffle the data! You'll lose the label ordering\n",
    "generator = image.ImageDataGenerator()\n",
    "batches = generator.flow_from_directory(path + 'train', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "val_batches = generator.flow_from_directory(path + 'valid', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "test_batches = generator.flow_from_directory(path + 'test', target_size=(224, 224), class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "from keras.utils.np_utils import to_categorical\n",
    "(val_classes, trn_classes, val_labels, trn_labels) = \\\n",
    "(val_batches.classes, batches.classes, to_categorical(val_batches.classes), to_categorical(batches.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/5\n",
      "20812/20812 [==============================] - 31s - loss: 108.4324 - acc: 0.5838 - val_loss: 36.9812 - val_acc: 0.7049\n",
      "Epoch 2/5\n",
      "20812/20812 [==============================] - 31s - loss: 17.0935 - acc: 0.8159 - val_loss: 7.7838 - val_acc: 0.7100\n",
      "Epoch 3/5\n",
      "20812/20812 [==============================] - 31s - loss: 4.4639 - acc: 0.8377 - val_loss: 3.6446 - val_acc: 0.7139\n",
      "Epoch 4/5\n",
      "20812/20812 [==============================] - 31s - loss: 2.6589 - acc: 0.8356 - val_loss: 2.8867 - val_acc: 0.7152\n",
      "Epoch 5/5\n",
      "20812/20812 [==============================] - 31s - loss: 2.3435 - acc: 0.8276 - val_loss: 2.7126 - val_acc: 0.7190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd78f7caef0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "model_fc2.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_fc2.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=5, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 31s - loss: 3.3993 - acc: 0.7616 - val_loss: 3.2209 - val_acc: 0.7062\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 31s - loss: 2.9087 - acc: 0.7456 - val_loss: 3.0185 - val_acc: 0.6986\n",
      "Epoch 3/4\n",
      "15296/20812 [=====================>........] - ETA: 7s - loss: 2.7969 - acc: 0.7510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b4fc48d06c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_val_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/envs/dl3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/dl3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/dl3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/dl3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/dl3/lib/python3.5/site-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_fc2.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.5555 - acc: 0.8581 - val_loss: 0.9640 - val_acc: 0.7642\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.4709 - acc: 0.8802 - val_loss: 0.9563 - val_acc: 0.7699\n",
      "Epoch 3/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.3984 - acc: 0.8981 - val_loss: 0.9489 - val_acc: 0.7672\n",
      "Epoch 4/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.3443 - acc: 0.9121 - val_loss: 0.9475 - val_acc: 0.7716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd78d784940>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fc2.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.2979 - acc: 0.9252 - val_loss: 0.9426 - val_acc: 0.7727\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.2612 - acc: 0.9334 - val_loss: 0.9443 - val_acc: 0.7759\n",
      "Epoch 3/4\n",
      "20812/20812 [==============================] - 23s - loss: 0.2334 - acc: 0.9413 - val_loss: 0.9485 - val_acc: 0.7727\n",
      "Epoch 4/4\n",
      "20812/20812 [==============================] - 22s - loss: 0.1997 - acc: 0.9525 - val_loss: 0.9486 - val_acc: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd78d784470>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fc2.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20812 samples, validate on 3673 samples\n",
      "Epoch 1/4\n",
      "20812/20812 [==============================] - 21s - loss: 0.4855 - acc: 0.8855 - val_loss: 1.3324 - val_acc: 0.7457\n",
      "Epoch 2/4\n",
      "20812/20812 [==============================] - 21s - loss: 0.4494 - acc: 0.8936 - val_loss: 1.3485 - val_acc: 0.7367\n",
      "Epoch 3/4\n",
      "20812/20812 [==============================] - 21s - loss: 0.3998 - acc: 0.9065 - val_loss: 1.3356 - val_acc: 0.7416\n",
      "Epoch 4/4\n",
      "20812/20812 [==============================] - 21s - loss: 0.3683 - acc: 0.9118 - val_loss: 1.3877 - val_acc: 0.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd79b8607f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fc2.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=4, validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 161 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "j = 0\n",
    "for i in range(1000):\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl3]",
   "language": "python",
   "name": "conda-env-dl3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
